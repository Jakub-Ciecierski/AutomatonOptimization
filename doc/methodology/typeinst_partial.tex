
\documentclass[runningheads,a4paper]{llncs}
\usepackage[margin=0.5in]{geometry}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url} % for bibliograpy links
\urlstyle{same}  % (for bibliography links

\usepackage{amsmath,amssymb}

\usepackage{color}

\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}
\vspace{-100pt}
\mainmatter

\title{Algorithms and Computability \\Methodology}

\titlerunning{Algorithms and Computability}

\author{Jakub Ciecierski \and Bartlomiej Dybisz}

\authorrunning{Algorithms and Computability}


\toctitle{Algorithms and Computability}
\tocauthor{Methodology}

\maketitle

\abstract{} Following work addresses the problem of finding a way to construct Deterministic Finite Automaton accepting some arbitrary regular language L. The only thing that we know is a tool, which for two words over alphabet of L is able to determine if they are in relation induced by language or not. Although at this point problem may seem vague, presented document tries to explain theory behind it, task itself and approach taken to solve it. 

\smallskip
\noindent \textbf{Keywords.} Deterministic Finite Automata, Regular Language, Relation Induced bv Language, Myhill-Nerode Theorem, Particle Swarm Optimization

%---------------------------------------------------------------------

\section{Introduction}
Following paper is devoted to methodology description. Methodology concerns project realized during Algorithms and Computability subject at Warsaw University of Technology. Such a paper is crucial, because it helps us to wrap up ideas and to present them in a transparent way. In addition, it should speed up the process of implementation and elevate awareness of what exactly is going on.
\paragraph{}
Work has been structured as follows: section \ref{section:objectives} describes general assumptions of the problem along with necessary definitions and theorems. Basically it helps to grasp the idea of the task.
Section \ref{section:methodology} on the other hand, dives directly into implementation. It supplements the reader with knowledge of mathematical objects and data structures needed to thoroughly understanding the approach taken to solve our task. 

\section{Objective} \label{section:objectives}
To start with, one need to be familiar with Myhill-Nerode theorem and the definition of relation induced by language. Since they are playing vital role in understanding the problem, both are presented below with some short description. 

\begin{definition}
Relation induced by language $L$ is a binary relation $R_{L}$ in the set of words over alphabet of $L$ such that:
\[
(\forall{u,v \in \Sigma^{*}})(u R_{L} v \equiv ((\forall z \in \Sigma^{*}) uz \in L \Leftrightarrow vz \in L))
\]
\end{definition}
What is more, we know that $R_{L}$ is an equivalence relation, hence it divides $\Sigma^{*}$ into equivalence classes.

\paragraph{}
In the theory of formal languages, the $Myhill-Nerode$ theorem provides a necessary and sufficient condition for a language to be regular. The theorem is named for John Myhill and Anil Nerode, who proved it at the University of Chicago in 1958 (Nerode 1958) \cite{Myhill_Nerode}.

\begin{theorem}[Myhill-Nerode Theorem]\label{Theorem:Myhill_Nerode}
The following conditions are equivalent:
\begin{enumerate}
\item a language $L$ is accepted by a deterministic finite automaton $M = (Q,\Sigma,\delta,q_0,F)$,
\item a language $L$ is a union of some classes of a right invariant equivalence relation with finite index,
\item the relation $R_{L}$ induced by a language $L$ has finite index.
\end{enumerate}
\end{theorem}

\subsection{Problem Description} \label{sub:definition}
General description of problem is as follows:

\begin{description}
  \item[What Do We Have]: 
   	\begin{itemize}
		\item Regular language $L$
		\item Some tool, which answers question "$x R_{L} y$?" for $x,y \in \Sigma^{*}$
	\end{itemize}
  \item[What We Should Do]:
    \begin{itemize}
		\item Construct Deterministic Finite Automaton (DFA) accepting $L$ (or find automaton close to exact one)
	\end{itemize}
 \end{description}


Since 'a tool' is rather an abstract concept in terms of language theory, we need to adapt it to our needs. From theorem \ref{Theorem:Myhill_Nerode}, we know that if language is regular (and the one given to us is) then it has an Deterministic Finite Automaton, let us say $T$, which accepts it. By accepting we mean that for any word $w \in \Sigma^{*}$, $T$ is able to determine whether $w \in L$ or not. 

Now for our purposes we will assume that $T$ has a following behaviour for any $x,y \in \Sigma^{*}$:
\begin{itemize}
  \item if both computations of $T$ for words $x$ and $y$ end in the same state $\Rightarrow$ $x R_{L} y$
  \item if both computations of $T$ for words $x$ and $y$ end in different states $\Rightarrow$ $\thicksim x R_{L} y$
\end{itemize}



%---------------------------------------------------------------------
\section{Methodology} \label{section:methodology}

%---------------------------------------------------------------------
%---------------------------------------------------------------------
\subsection{Automaton Representation} \label{sec:autom}

Automaton is a system of five fields:
\begin{center}
	$A = (Q, \Sigma, \delta, q_0, F)$
\end{center}

where \\
$Q$ - finite set of states. \\
$\Sigma$ - Finite input alphabet. \\
$\delta$ - transition function. $\delta: Q \times \Sigma \rightarrow Q$ \\
$q_0$ - the initial state. $q_0 \in Q$ \\
$F$ - Set of accepting states. $F \subseteq Q$ \\

Example of Automaton A- {\color{red}(TODO Place the state diagram here)}

Transition Table for A with $\delta: Q \times \Sigma \rightarrow Q$ 

\begin{figure}
\begin{center}

	\setlength{\tabcolsep}{4pt}
	\renewcommand{\arraystretch}{1.5}
	
	\begin{tabular}{|P{1.0cm} || P{0.6cm} | P{0.6cm} |}
	\hline
	$\delta$ & a & b \\
	\hline
	\hline
	$\rightarrow q^-$ 		& $q_0$ & $q_1$ \\
	\hline
	$q_0 \rightarrow$ 		& $q_R$ & $q_R$ \\
	\hline
	$q_1 \rightarrow$ 		& $q_1$ & $q_1$ \\
	\hline
	$q_R$  					& $q_R$ & $q_R$ \\
	\hline
	\end{tabular}

	
\caption{Transition table for A with $\delta: Q \times \Sigma \rightarrow Q$}
\label{fig:ttable_std}
\end{center}
\end{figure}


The binary representation of automaton might perhaps provide more adequate solution for a computer. Thus a new transition function is defined, $\delta^{'}: Q \times \Sigma \times Q \rightarrow \{0,1\}$. It simply provides an answer whether there exists a transition between two states for a given symbol. For example, by looking at figure~\ref{fig:ttable_std} we can define value for $\delta^{'}(q^-,a,q^0) = 1$, since we there exists a transition from $q^-$ to $q^0$ through symbol $a$. The entire automaton is presented in figure~\ref{fig:ttable_bin}.



\begin{figure}
\begin{center}

	\setlength{\tabcolsep}{4pt}
	\renewcommand{\arraystretch}{1.4}

	\begin{tabular}{|P{1.0cm} || P{0.8cm} | P{0.8cm} | P{0.8cm} | P{0.8cm}|}
	\hline
	a & $\rightarrow q^-$ & $q_0 \rightarrow$ & $q_1 \rightarrow$ & $q_R$ \\
	\hline
	\hline
	$\rightarrow q^-$ 		& $0$ & $1$ & $0$ & $0$ \\
	\hline
	$q_0 \rightarrow$ 		& $0$ & $0$ & $0$ & $1$ \\
	\hline
	$q_1 \rightarrow$ 		& $0$ & $0$ & $1$ & $0$ \\
	\hline
	$q_R$  					& $0$ & $0$ & $0$ & $1$ \\
	\hline
	
	\end{tabular}
	\hspace*{1 cm}
	\begin{tabular}{|P{1.0cm} || P{0.8cm} | P{0.8cm} | P{0.8cm} | P{0.8cm}|}
	\hline
	b & $\rightarrow q^-$ & $q_0 \rightarrow$ & $q_1 \rightarrow$ & $q_R$ \\
	\hline
	\hline
	$\rightarrow q^-$ 		& $0$ & $0$ & $1$ & $0$ \\
	\hline
	$q_0 \rightarrow$ 		& $0$ & $0$ & $0$ & $1$ \\
	\hline
	$q_1 \rightarrow$ 		& $0$ & $0$ & $1$ & $0$ \\
	\hline
	$q_R$  					& $0$ & $0$ & $0$ & $1$ \\
	\hline
	
	\end{tabular}
	
\caption{Transition tables for symbols $a$ and $b$, making up the entire transition function $\delta^{'}: Q \times \Sigma \times Q \rightarrow \{0,1\}$}

\label{fig:ttable_bin}
\end{center}
\end{figure}

It is important to note that to preserve determinism, there must exist exactly one transition from any state for a given symbol. In other words in each transition table for $\delta^{'}$ a single row must be a sequence of $0s$ and a single digit $1$.




%---------------------------------------------------------------------
%---------------------------------------------------------------------
\subsection{Particle Swarm Optimization}
In the Particle Swarm Optimization (PSO) we look for optimal solution of the problem in the solution space. Each solution is called a particle and it consists of $fitness$ value which is evaluated by the fitness function, position $X_p$ and velocity vector $V_p$ which lets the particle travel through the solution space (cf. \cite{pso_origin}).

PSO is initialized with random group of particles. It then searches for the optimal solution by updating generations.
In each iteration $t$, the particles are updated by calculating new fitness and velocity which in turn is applied to update new position of the particle.

$X_p(t)$ will denote the position of particle $p$ at time $t$, i.e. the $t$-th iteration. Same notation applies to the velocity vector $V_p(t)$.

The following illustrates the flow of the PSO algorithm:

\begin{center}

\begin{enumerate}
	\item Initialize random group of particles. {\color{red} TODO - MAYBE NOT SO RANDOM ? CAN WE USE KNOWLEDGE OF PREVIOUS PSO INSTANCE ?}
	\item \label{itm:pso_iter} Calculate the fitness value of each particle $p$ using fitness function.
		
	\item Each particle $p$ compares newly computed fitness value to the best one obtained so far, the new best fitness value is stored. Additionally we store two positions called $pbest_p$ and $lbest_p$. The former one represents the position of the particle $p$ having the best fitness value so far. The latter position is the local best position taken from a neighbourhood of the particle $p$. Concept of neighbourhood shall be discussed in the next section.
	
	\item Update velocity and position of each particle.
	
	\item Repeat~\ref{itm:pso_iter}. until an ending criterion is met.
	
\end{enumerate}

\end{center}


%---------------------------------------------------------------------
%---------------------------------------------------------------------
%---------------------------------------------------------------------
\subsubsection{Representing the solution}

Solution that the PSO is trying to find is an automaton. Let us recall that automaton is a system: $A = (Q, \Sigma, \delta, q_0, F)$. In a single PSO instance we assume that a set of states $Q$ and alphabet $\Sigma$ is invariant. Through the nature of our problem we also can conclude that distinguishing accepting states is not necessary. ({\color{red} TODO refer to problem description, aka the relation})
Thus, we only need to represent the transition function and initial state. The following description formulates such representation.

Let us denote the number of states by $n = |Q|$, and number of symbols in alphabet by $r = |\Sigma|$. Further, we shall enumerate all states 	$Q = \{q_1, q_2, \ldots, q_n\}$, and all the symbols in the alphabet 	$\Sigma = \{x_1, x_2, \ldots, x_r\}$.

We now turn to the binary approach of transition function $\delta^{'}$ described in \ref{sec:autom} presentation 




Each table in the new approach has size $n^2$. We have r tables.

Thus we can easily decode the automaton as follows:
\begin{itemize}
\item To decode one table of symbol $x_l$ create a vector $V_{x_l}$ representing that table:
	\begin{itemize}
		\item From each $q_i$ row take an index $j$ for $j = 1,2,..,n$ of the element of this row having value $1$, i.e. there exists a transition $\delta(q_i, x_l, q_j) = 1$.
		\item If the transition to accepting state is possible, i.e. if the element from current state to accepting state has value 1 then take the negative value of that index. 2 becomes -2, 1 becomes -1 etc. {\color{red} TODO, We don't really need accepting states, all we need to know is the state that automaton finishes computation in}
		\item Append it to the vector $V_{x_l}$
	\end{itemize}
\end{itemize}

Thus the first table in figure~\ref{fig:ttable_bin}, showing the transitions for symbol $a$ can be represented as follows:

\begin{center}
	$V_a = (-2, 4, -3, 4)$
\end{center}

Similarly vector $V_b$:

\begin{center}
	$V_b = (-3, 4, -3, 4)$
\end{center}

Now to create the vector $V$ of entire transition function we simply append the to vectors $V_a$, $V_b$.

\begin{center}
	$V = (-2,4,-3,4,-3,4,-3,4)$
\end{center}

Properties of vector $V$
\begin{itemize}
	\item It is constructed by appending $r$ vectors $V_{x_1}, V_{x_2}, \ldots, V_{x_{r}}$ each with $n$ dimensions. Thus $V$ has $n * r$ dimensions.
	
%	\item The first integer number $k_{i,1}$ of each sub vector $V_{x_i}$ is the transition for initial state, symbol $x_i$ and state $q_{|k_{i,1}|}$.
\end{itemize}

%---------------------------------------------------------------------
%---------------------------------------------------------------------
%---------------------------------------------------------------------
\subsubsection{Initialization}

%---------------------------------------------------------------------
%---------------------------------------------------------------------
%---------------------------------------------------------------------
\subsubsection{Fitness Function}
It describes how well a particle (in our case an automaton) reflects the goal. Since all we know about our target DFA (accepting language $L$) is a tool described in subsection \ref{sub:definition}, we decided to base our fitness function on knowledge about relation $R_{L}$. 
\paragraph{}
Measure is fairly simple: for a given test set of pairs of words, we check how many of them are correctly classified to equivalence class (using $R_{L} relation$) and divide this amount by number of all pairs. We will use an example to illustrate the process.
Let us assume that we have following pairs ${(x_1,y_1), (x_2,y_2), (x_3, y_3), (x_4, y_4), (x_5, y_5)} $


%---------------------------------------------------------------------
%---------------------------------------------------------------------
%---------------------------------------------------------------------
\subsubsection{Updating the particle}


% Naive approach

%The naive approach of updating the particles' positions was proposed in the original PSO algorithm~\cite{pso_origin}.

%\begin{equation}
%		V_p(t+1) = V_p(t) + c_1 * \mu_1 *(pbest_p - X_p(t)) + c_2 * \mu_2 *(lbest_p - X_p(t))
%	\end{equation}
%	
%	\begin{equation}
%		X_p(t+1) = X_p(t) + V_p(t)
%	\end{equation}
%	where:\\
%	$c_1, c_2$ are the constant learning factors.\\
%	$\mu_1, \mu_2$ are random numbers in the range [0,1]. {\color{red} TODO What distribution function - uniform ?} \\

The following method of updating the particles has its origins in the Standard Particle Swarm Optimization version 2011 (cf. \cite{pso_11})

Let $G_p(t)$ be the centre of gravity of the three points:
\begin{enumerate}
	\item Current position. $X_p(t)$
	
	\item Point a bit "beyond" $pbest_p$. $Y_{p1}(t) = c*(pbest_p-X_p(t))$
	
	\item Point a bit "beyond" $lbest_p$. $Y_{p2}(t) = c*(lbest_p-X_p(t))$
			
\end{enumerate}

The constant $c = \frac{1}{2} + ln(2)$ together with the inertia parameter that weights the particle's velocity $\omega = \frac{1}{2 * ln(2)}$ was proposed by Clerc in~\cite{pso_anal}  used in further equations. 

Formally $G_p(t)$ it is defined by the following formula 
\begin{equation}
	G_p(t) = \frac{X_p(t) + Y_{p1}(t) + Y_{p2}(t)} {3}
\end{equation}

We now define a random point $X^{'}_p$ in the hypersphere
\begin{center}
	$\mathcal{H}_p(G_p, d(G_p, X_p))$ 
\end{center}
of centre $G_p$ and of radius $d(G_p, X_p)$ where the function $d$ is an euclidean distance between two points. The time $t$ has been omitted for simplicity.

The velocity update is computed by
\begin{equation}
	V_p(t+1) = \omega * V_p(t) + X^{'}_p(t) - X_p(t)
\end{equation}
Thus the position is updated by the equation

\begin{equation}
	X_p(t+1) = \omega * V_p(t) + X^{'}_p(t)
\end{equation}

This method grants adequate definitions for $exploitation$ and $exploration$. Namely the exploitation occurs when $X_p(t+1)$ is inside atleast one hypersphere $\mathcal{H}_q$, otherwise we recognize exploration.

%---------------------------------------------------------------------
%---------------------------------------------------------------------
%---------------------------------------------------------------------
\subsubsection{Convergence}


%---------------------------------------------------------------------
%---------------------------------------------------------------------
%---------------------------------------------------------------------
\subsubsection{Size of the swarm}



\begin{thebibliography}{9}
\bibitem{Myhill_Nerode}
\url{https://en.wikipedia.org/wiki/Myhill-Nerode_theorem}

\bibitem{pso_origin} 
Eberhart, R. C. and Kennedy, J. A new optimizer using particle swarm theory. Proceedings of the sixth international symposium on micro machine and human science pp. 39-43. IEEE service center, Piscataway, NJ, Nagoya, Japan, 1995.

\bibitem{pso_bias} 
William M. Spears, Derek T. Green and Diana F. Spears. Biases in particle swarm optimization. International Journal of Swarm Intelligence Research, 1(2):34-57, 2010.

\bibitem{pso_anal}
Maurice Clerc. Stagnation analysis in particle swarm optimization or what happens when nothing happens, http://hal.archives-ouvertes.fr/hal-00122031. Technical report, 2006.

\bibitem{pso_11}
M. Clerc. (2011). Standard Particle Swarm Optimisation Available: http://hal.archives-ouvertes.fr/hal-00764996 

\end{thebibliography}

\end{document}